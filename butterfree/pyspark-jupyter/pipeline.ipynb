{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "\n",
    "When the data grows fast, performing ETL pipelines for multiple machine learning projects becomes expensive since repetitive operations. A feature store is a solution to this problem. It's possible to reuse the features in different projects and don't need to repeat similar processes in other projects.\n",
    "\n",
    "This tutorial will cover how to create a feature store for Starbucks transactions. We will build ETLs pipelines using Butterfree library to upload data to a Feature Store so that data can be provided for machine learning algorithms, even for training or for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:\n",
    "Simulating the following scenario:\n",
    "\n",
    "- We have a streaming JSON data source with events of starbucks orders being captured in real time.\n",
    "- We have a csv data set with more information about drinks.\n",
    "\n",
    "\n",
    "Objective: \n",
    "\n",
    "We want to parse the JSON from the streaming source, performing aggregations operations, and store all rows in a cheap structure(like s3) and get more recent transactions on a low latency database like Cassandra.\n",
    "\n",
    "We desire to have an output with the schema:\n",
    "\n",
    "- **id_employer**: int\n",
    "- **name_employer**: string\n",
    "- **name_client**: string\n",
    "- **payment**: string\n",
    "- **timestamp**: timestamp\n",
    "- **product_name**: timestamp\n",
    "- **product_size**: string\n",
    "- **product_price**: int\n",
    "- **percent_carbo**: float\n",
    "- **final_price**: float\n",
    "\n",
    "\n",
    "The following code blocks will show how to generate this feature set using Butterfree library using the above architecture:\n",
    "\n",
    "- Apache Kafka as data sources (Streaming input data);\n",
    "\n",
    "- A hive metastore to store metadata (like their schema and location) in a relational database.(For this tutorial we will use Postgresql)\n",
    "- Apache Cassandra to store more recent data.\n",
    "- Amazon S3 to store historical features or table views for debug mode.\n",
    "\n",
    "<img src=\"arc.png\">\n",
    "\n",
    "\n",
    "\n",
    "<b>Historical Feature Store:</b> all features calculated over time;\n",
    "\n",
    "<b>Online Feature Store:</b> hot/latest(last record by key) data stored at a low latency data storage(Cassandra).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "<b>In this tutorial, the historical data will be stored locally. However, you can easily add an s3 bucket. \n",
    "    </b>\n",
    "    \n",
    "  <b> Check the documentation here https://butterfree.readthedocs.io/en/latest/configuration.html?highlight=s3#historical-feature-store-spark-metastore-and-s3  </b>\n",
    "\n",
    "<b>We will do a batch process, but you can switch to online processing with minor modifications\n",
    "    </b>\n",
    "    \n",
    "<b> Check the documentation here https://butterfree.readthedocs.io/en/latest/stream.html </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master local[6] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0,com.datastax.spark:spark-cassandra-connector_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.2.2 --conf 'spark.driver.extraJavaOptions=-Dhttp.proxyHost=192.168.5.8 -Dhttp.proxyPort=3128 -Dhttp.nonProxyHosts=localhost|127.0.0.1 -Dhttps.proxyHost=192.168.5.8 -Dhttps.proxyPort=3128 -Dhttps.nonProxyHosts=localhost|127.0.0.1' pyspark-shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Instance\n",
    "\n",
    "Connecting to hive metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "22/12/28 18:48:00 WARN Utils: Your hostname, ANM-HOANGP46 resolves to a loopback address: 127.0.1.1; using 192.168.6.138 instead (on interface enx000ec6c370bb)\n",
      "22/12/28 18:48:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hoang/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/hoang/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hoang/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c2e2a41c-5882-41a4-b0db-743c28ba7e8b;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/hoang/.local/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.0 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.2.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.2.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 576ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.2.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.2.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   33  |   0   |   0   |   2   ||   31  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c2e2a41c-5882-41a4-b0db-743c28ba7e8b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 31 already retrieved (0kB/14ms)\n",
      "22/12/28 18:48:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/home/hoang/.local/lib/python3.8/site-packages/pyspark/sql/context.py:601: FutureWarning: HiveContext is deprecated in Spark 2.0.0. Please use SparkSession.builder.enableHiveSupport().getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# setup spark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import session, SparkSession\n",
    "from pyspark.sql import HiveContext\n",
    "# butterfree spark client\n",
    "from butterfree.clients import SparkClient\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Feature Store\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"hive.metastore.uris\", \"thrift://localhost:9083\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate())\n",
    "\n",
    "sc=spark.sparkContext\n",
    "\n",
    "# client\n",
    "spark_client = SparkClient()\n",
    "hive_context = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/28 18:48:04 WARN Utils: Your hostname, ANM-HOANGP46 resolves to a loopback address: 127.0.1.1; using 192.168.6.138 instead (on interface enx000ec6c370bb)\n",
      "22/12/28 18:48:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hoang/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.0\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.17\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2021-10-06T12:46:30Z\n",
      "Revision 5d45a415f3a29898d92380380cfd82bfc7f579ea\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n",
      "pyspark==3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pyspark --version && pip3 freeze | grep pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract\n",
    "\n",
    "First, we need to define our data schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, StructType, StructField, DoubleType\n",
    "\n",
    "schema_kafka = StructType([StructField('name_employer', StringType(), True),\n",
    "                          StructField('id_employer', IntegerType(), True),\n",
    "                          StructField('name_client', StringType(), True),\n",
    "                          StructField('transaction_id', IntegerType(), True),\n",
    "                          StructField('payment', StringType(), True),\n",
    "                          StructField('timestamp', StringType(), True),\n",
    "                          StructField('product_name', StringType(), True),\n",
    "                          StructField('product_size', StringType(), True),\n",
    "                          StructField('product_price', DoubleType(), True),\n",
    "                          StructField('percent_discount', IntegerType(), True)])\n",
    "\n",
    "\n",
    "schema_file = StructType([StructField('name', StringType(), True),\n",
    "                         StructField('calories', IntegerType(), True),\n",
    "                         StructField('fat_g', IntegerType(), True),\n",
    "                         StructField('carb_g', IntegerType(), True),\n",
    "                         StructField('fiber_g', IntegerType(), True),\n",
    "                         StructField('protein', IntegerType(), True),\n",
    "                         StructField('sodium', IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting with cassandra database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from butterfree.extract import Source\n",
    "from butterfree.extract.readers import FileReader\n",
    "from butterfree.extract.readers import KafkaReader\n",
    "\n",
    "kafka_reader = KafkaReader(\n",
    "    id=\"events\",\n",
    "    topic=\"queueing.transactions\",\n",
    "    value_schema=schema_kafka,\n",
    "    connection_string=\"localhost:9092\",\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "readers = [\n",
    "    kafka_reader,\n",
    "    FileReader(id=\"nutrients\", path=\"data/starbucks-menu-nutrition-drinks.csv\", format=\"csv\", schema=schema_file)\n",
    "]\n",
    "\n",
    "query = \"\"\"\n",
    "select\n",
    "    *\n",
    "from\n",
    "    events\n",
    "    join nutrients\n",
    "        on events.product_name = nutrients.name\n",
    "\"\"\"\n",
    "\n",
    "source = Source(readers=readers, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "source_df = source.construct(spark_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing that it is a Spark's streaming df\n",
    "source_df.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name_employer: string (nullable = true)\n",
      " |-- id_employer: integer (nullable = true)\n",
      " |-- name_client: string (nullable = true)\n",
      " |-- transaction_id: integer (nullable = true)\n",
      " |-- payment: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_size: string (nullable = true)\n",
      " |-- product_price: double (nullable = true)\n",
      " |-- percent_discount: integer (nullable = true)\n",
      " |-- kafka_metadata: struct (nullable = false)\n",
      " |    |-- key: string (nullable = true)\n",
      " |    |-- topic: string (nullable = true)\n",
      " |    |-- value: string (nullable = true)\n",
      " |    |-- partition: integer (nullable = true)\n",
      " |    |-- offset: long (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- timestampType: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- calories: integer (nullable = true)\n",
      " |-- fat_g: integer (nullable = true)\n",
      " |-- carb_g: integer (nullable = true)\n",
      " |-- fiber_g: integer (nullable = true)\n",
      " |-- protein: integer (nullable = true)\n",
      " |-- sodium: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "source_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "- At the transform part, a set of `Feature` objects is declared.\n",
    "- An Instance of `FeatureSet` is used to hold the features.\n",
    "- A `FeatureSet` can only be created when it is possible to define a unique tuple formed by key columns and a time reference. This is an **architectural requirement** for the data. So least one `KeyFeature` and one `TimestampFeature` is needed.\n",
    "- Every `Feature` needs a unique name, a description, and a data-type definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "from butterfree.transform import FeatureSet\n",
    "from butterfree.transform.features import Feature, KeyFeature, TimestampFeature\n",
    "from butterfree.transform.transformations import SQLExpressionTransform, SparkFunctionTransform, CustomTransform\n",
    "from butterfree.transform.transformations.h3_transform import H3HashTransform\n",
    "from butterfree.constants import DataType\n",
    "from butterfree.transform.utils import Function\n",
    "\n",
    "\n",
    "def divide(df, parent_feature, column1, column2):\n",
    "    name = parent_feature.get_output_columns()[0]\n",
    "    df = df.withColumn(name, F.col(column1) / F.col(column2))\n",
    "    return df\n",
    "\n",
    "\n",
    "keys = [\n",
    "    KeyFeature(\n",
    "        name=\"id_employer\",\n",
    "        description=\"Unique identificator code for employer.\",\n",
    "        from_column=\"id_employer\",\n",
    "        dtype=DataType.INTEGER,\n",
    "    )\n",
    "]\n",
    "\n",
    "# from_ms = True because the data originally is not in a Timestamp format.\n",
    "ts_feature = TimestampFeature(from_column=\"timestamp\")\n",
    "\n",
    "features = [\n",
    "    Feature(\n",
    "        name=\"name_employer\",\n",
    "        description=\"name_employer\",\n",
    "        dtype=DataType.STRING,\n",
    "    ),\n",
    "    Feature(\n",
    "        name=\"name_client\",\n",
    "        description=\"name_client\",\n",
    "        dtype=DataType.STRING,\n",
    "    ),\n",
    "    Feature(\n",
    "        name=\"product_name\",\n",
    "        description=\"product_name.\",\n",
    "        dtype=DataType.STRING,\n",
    "    ),\n",
    "    Feature(\n",
    "        name=\"product_price\",\n",
    "        description=\"product_price.\",\n",
    "        dtype=DataType.FLOAT,\n",
    "    ),\n",
    "    Feature(\n",
    "        name=\"payment\",\n",
    "        description=\"payment.\",\n",
    "        dtype=DataType.STRING,\n",
    "    ),\n",
    "    Feature(\n",
    "        name=\"calories\",\n",
    "        description=\"calories\",\n",
    "        dtype=DataType.INTEGER,\n",
    "    ),\n",
    "    # custom transformation\n",
    "    Feature(\n",
    "           name=\"percent_carbo\",\n",
    "           description=\"percent_carbo\",\n",
    "           transformation=CustomTransform(transformer=divide, column1=\"carb_g\", column2=\"calories\"), \n",
    "           dtype=DataType.FLOAT,\n",
    "    ),\n",
    "    # SQL transformation\n",
    "    Feature(\n",
    "           name=\"final_price\",\n",
    "           description=\"percent_carbo\",\n",
    "           transformation=SQLExpressionTransform(\"product_price * ((100 - percent_discount)/100)\"), \n",
    "           dtype=DataType.FLOAT,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# events will be sotred in our metasotore as a table. You can acess starbucks_order_events \n",
    "feature_set = FeatureSet(\n",
    "    name=\"starbucks_order_events\",\n",
    "    entity=\"events\",  # entity: to which \"business context\" this feature set belongs\n",
    "    description=\"Features describring events about starbucks store.\",\n",
    "    keys=keys,\n",
    "    timestamp=ts_feature,\n",
    "    features=features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/workspace/feature_store/feature-store-hadoop/butterfree/transform/features/feature.py:138: UserWarning: The column name id_employer already exists in the dataframe and will be overwritten with another column.\n",
      "  warnings.warn(\n",
      "/home/hoang/workspace/feature_store/feature-store-hadoop/butterfree/transform/features/feature.py:138: UserWarning: The column name timestamp already exists in the dataframe and will be overwritten with another column.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "feature_set_df = feature_set.construct(source_df, spark_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_employer: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- name_employer: string (nullable = true)\n",
      " |-- name_client: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_price: float (nullable = true)\n",
      " |-- payment: string (nullable = true)\n",
      " |-- calories: integer (nullable = true)\n",
      " |-- percent_carbo: double (nullable = true)\n",
      " |-- final_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "feature_set_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id_employer,IntegerType,true),StructField(timestamp,TimestampType,true),StructField(name_employer,StringType,true),StructField(name_client,StringType,true),StructField(product_name,StringType,true),StructField(product_price,FloatType,true),StructField(payment,StringType,true),StructField(calories,IntegerType,true),StructField(percent_carbo,DoubleType,true),StructField(final_price,DoubleType,true)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_employer</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name_employer</th>\n",
       "      <th>name_client</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>payment</th>\n",
       "      <th>calories</th>\n",
       "      <th>percent_carbo</th>\n",
       "      <th>final_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 12:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Aaron Murphy</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.45</td>\n",
       "      <td>debit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>3.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 19:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Angela Leach</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 09:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Brandon Monroe</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>3.75</td>\n",
       "      <td>credit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 21:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Daniel Garcia</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.25</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-03 16:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Diana Jones</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>4.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-02 13:04:05</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>Richard Dodson</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.75</td>\n",
       "      <td>credit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>4.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 21:04:05</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>Shane Mccormick</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>debit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 13:04:05</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>Shirley Wang</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.45</td>\n",
       "      <td>credit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-02 07:04:05</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>Timothy Sanchez</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.75</td>\n",
       "      <td>cash</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 10:04:05</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>William Kirk</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>4.185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_employer           timestamp name_employer      name_client  \\\n",
       "0             1 2020-08-04 12:04:05          Alex     Aaron Murphy   \n",
       "1             1 2020-08-02 19:04:05          Alex     Angela Leach   \n",
       "2             1 2020-08-02 09:04:05          Alex   Brandon Monroe   \n",
       "3             1 2020-08-02 21:04:05          Alex    Daniel Garcia   \n",
       "4             1 2020-08-03 16:04:05          Alex      Diana Jones   \n",
       "..          ...                 ...           ...              ...   \n",
       "95            0 2020-08-02 13:04:05        Alicia   Richard Dodson   \n",
       "96            0 2020-08-04 21:04:05        Alicia  Shane Mccormick   \n",
       "97            0 2020-08-04 13:04:05        Alicia     Shirley Wang   \n",
       "98            0 2020-08-02 07:04:05        Alicia  Timothy Sanchez   \n",
       "99            0 2020-08-04 10:04:05        Alicia     William Kirk   \n",
       "\n",
       "             product_name  product_price  payment  calories  percent_carbo  \\\n",
       "0       Caramel Macchiato           4.45    debit       250       0.140000   \n",
       "1    Cinnamon Dolce Latte           3.65   credit       260       0.153846   \n",
       "2       Caramel Macchiato           3.75   credit       250       0.140000   \n",
       "3    Cinnamon Dolce Latte           4.25   credit       260       0.153846   \n",
       "4    Cinnamon Dolce Latte           4.65   credit       260       0.153846   \n",
       "..                    ...            ...      ...       ...            ...   \n",
       "95  White Chocolate Mocha           4.75   credit       360       0.147222   \n",
       "96   Cinnamon Dolce Latte           3.65    debit       260       0.153846   \n",
       "97  White Chocolate Mocha           4.45   credit       360       0.147222   \n",
       "98  White Chocolate Mocha           4.75     cash       360       0.147222   \n",
       "99   Cinnamon Dolce Latte           4.65   credit       260       0.153846   \n",
       "\n",
       "    final_price  \n",
       "0         3.560  \n",
       "1         2.555  \n",
       "2         2.625  \n",
       "3         3.400  \n",
       "4         4.185  \n",
       "..          ...  \n",
       "95        4.275  \n",
       "96        2.920  \n",
       "97        3.115  \n",
       "98        3.800  \n",
       "99        4.185  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "- Using debug mode to create a temporary view with the historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from butterfree.load.writers import (\n",
    "    HistoricalFeatureStoreWriter,\n",
    "    OnlineFeatureStoreWriter,\n",
    ")\n",
    "from butterfree.load import Sink\n",
    "\n",
    "from butterfree.configs.db import CassandraConfig, MetastoreConfig\n",
    "from butterfree.load.writers import OnlineFeatureStoreWriter\n",
    "\n",
    "db_config  = CassandraConfig(\n",
    "    username=\"cassandra\", \n",
    "    password=\"mysecretpassword\",\n",
    "    host=\"localhost\",\n",
    "    keyspace=\"feature_store\",\n",
    "    stream_checkpoint_path=\"./\",\n",
    "    local_dc='datacenter1'\n",
    ")\n",
    "\n",
    "s3_config = MetastoreConfig(\n",
    "    path=\"featurestore\"\n",
    ")\n",
    "\n",
    "# writers = [HistoricalFeatureStoreWriter(debug_mode=True),OnlineFeatureStoreWriter(debug_mode=True)]\n",
    "# writers = [HistoricalFeatureStoreWriter(debug_mode=True),OnlineFeatureStoreWriter(db_config=db_config)]\n",
    "writers = [HistoricalFeatureStoreWriter(db_config=s3_config, database=\"default\"),OnlineFeatureStoreWriter(db_config=db_config)]\n",
    "\n",
    "sink = Sink(writers=writers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cassandra tables\n",
    "\n",
    "- Lets create a keyspace and a table to store the online features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS feature_store.starbucks_order_events (id_employer int PRIMARY KEY, timestamp timestamp, name_employer text, name_client text, product_name text, product_price float, payment text, calories int, percent_carbo double, final_price double);\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster, PlainTextAuthProvider\n",
    "\n",
    "keyspace = \"feature_store\"\n",
    "table_name = \"starbucks_order_events\"\n",
    "\n",
    "cassandra_mapping = {\n",
    "        \"TimestampType\": \"timestamp\",\n",
    "        \"BinaryType\": \"boolean\",\n",
    "        \"BooleanType\": \"boolean\",\n",
    "        \"DateType\": \"timestamp\",\n",
    "        \"DecimalType\": \"decimal\",\n",
    "        \"DoubleType\": \"double\",\n",
    "        \"FloatType\": \"float\",\n",
    "        \"IntegerType\": \"int\",\n",
    "        \"LongType\": \"bigint\",\n",
    "        \"StringType\": \"text\",\n",
    "        \"ArrayType(LongType,true)\": \"frozen<list<bigint>>\",\n",
    "        \"ArrayType(StringType,true)\": \"frozen<list<text>>\",\n",
    "        \"ArrayType(FloatType,true)\": \"frozen<list<float>>\",\n",
    "    }\n",
    "\n",
    "cluster = Cluster(['127.0.0.1'], auth_provider=PlainTextAuthProvider(username='cassandra', password='mysecretpassword'))\n",
    "session = cluster.connect()\n",
    "\n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS \"+ keyspace +\" WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'datacenter1' : 1 };\")\n",
    "\n",
    "sql = \", \".join([feature.name +str(\" \") + cassandra_mapping[str(feature.dataType)] for feature in feature_set_df.schema]).replace(\"id_employer int\", \"id_employer int PRIMARY KEY\")\n",
    "sql = \"CREATE TABLE IF NOT EXISTS {}.{} (\" + sql + \");\"\n",
    "sql = sql.format(keyspace, table_name)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(sql)\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from butterfree.pipelines import FeatureSetPipeline\n",
    "\n",
    "pipeline = FeatureSetPipeline(source=source, feature_set=feature_set, sink=sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/workspace/feature_store/feature-store-hadoop/butterfree/transform/features/feature.py:138: UserWarning: The column name id_employer already exists in the dataframe and will be overwritten with another column.\n",
      "  warnings.warn(\n",
      "/home/hoang/workspace/feature_store/feature-store-hadoop/butterfree/transform/features/feature.py:138: UserWarning: The column name timestamp already exists in the dataframe and will be overwritten with another column.\n",
      "  warnings.warn(\n",
      "22/12/28 18:48:17 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "22/12/28 18:48:19 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# asinc run when creating an in memory streaming view for sink \n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online features for cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Online Feature Store  table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_employer</th>\n",
       "      <th>calories</th>\n",
       "      <th>final_price</th>\n",
       "      <th>name_client</th>\n",
       "      <th>name_employer</th>\n",
       "      <th>payment</th>\n",
       "      <th>percent_carbo</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>4.185</td>\n",
       "      <td>Monica Wolf</td>\n",
       "      <td>Denver</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2020-08-05 08:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>2.920</td>\n",
       "      <td>Seth Allen</td>\n",
       "      <td>Alex</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2020-08-05 05:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>3.255</td>\n",
       "      <td>Anthony Gonzalez</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>debit</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2020-08-05 09:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>2.555</td>\n",
       "      <td>Antonio Jacobs</td>\n",
       "      <td>Julian</td>\n",
       "      <td>debit</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2020-08-05 00:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>3.115</td>\n",
       "      <td>Alicia Ellis</td>\n",
       "      <td>Mark</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2020-08-05 07:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>3.115</td>\n",
       "      <td>Stephen Lambert</td>\n",
       "      <td>Luiza</td>\n",
       "      <td>debit</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2020-08-05 04:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>3.560</td>\n",
       "      <td>Bethany Ryan</td>\n",
       "      <td>Cassandra</td>\n",
       "      <td>debit</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2020-08-04 23:04:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_employer  calories  final_price       name_client name_employer  \\\n",
       "0            5       260        4.185       Monica Wolf        Denver   \n",
       "1            1       260        2.920        Seth Allen          Alex   \n",
       "2            0       260        3.255  Anthony Gonzalez        Alicia   \n",
       "3            2       260        2.555    Antonio Jacobs        Julian   \n",
       "4            4       250        3.115      Alicia Ellis          Mark   \n",
       "5            6       250        3.115   Stephen Lambert         Luiza   \n",
       "6            3       360        3.560      Bethany Ryan     Cassandra   \n",
       "\n",
       "   payment  percent_carbo           product_name  product_price  \\\n",
       "0   credit       0.153846   Cinnamon Dolce Latte           4.65   \n",
       "1   credit       0.153846   Cinnamon Dolce Latte           3.65   \n",
       "2    debit       0.153846   Cinnamon Dolce Latte           4.65   \n",
       "3    debit       0.153846   Cinnamon Dolce Latte           3.65   \n",
       "4   credit       0.140000      Caramel Macchiato           4.45   \n",
       "5    debit       0.140000      Caramel Macchiato           4.45   \n",
       "6    debit       0.147222  White Chocolate Mocha           4.45   \n",
       "\n",
       "            timestamp  \n",
       "0 2020-08-05 08:04:05  \n",
       "1 2020-08-05 05:04:05  \n",
       "2 2020-08-05 09:04:05  \n",
       "3 2020-08-05 00:04:05  \n",
       "4 2020-08-05 07:04:05  \n",
       "5 2020-08-05 04:04:05  \n",
       "6 2020-08-04 23:04:05  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\">>> Online Feature Store  table:\")\n",
    "\n",
    "from cassandra.cluster import Cluster, PlainTextAuthProvider\n",
    "cluster = Cluster(['127.0.0.1'], auth_provider=PlainTextAuthProvider(username='cassandra', password='mysecretpassword'))\n",
    "session = cluster.connect()\n",
    "df = session.execute(\"SELECT * FROM feature_store.starbucks_order_events\")\n",
    "cluster.shutdown()\n",
    "# Create data frame\n",
    "df = spark.createDataFrame(df)\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing metastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  default|starbucks_order_e...|      false|\n",
      "|         |              events|       true|\n",
      "|         |           nutrients|       true|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hive_context.sql(\"show tables;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Historical Feature Store:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_employer</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name_employer</th>\n",
       "      <th>name_client</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>payment</th>\n",
       "      <th>calories</th>\n",
       "      <th>percent_carbo</th>\n",
       "      <th>final_price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 12:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Aaron Murphy</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.45</td>\n",
       "      <td>debit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>3.560</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 23:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Eugene Maddox</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.75</td>\n",
       "      <td>credit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>4.275</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 08:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Jonathan Bradley</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>3.75</td>\n",
       "      <td>cash</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 05:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Thomas Pace</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>3.75</td>\n",
       "      <td>debit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 20:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Thomas Stein</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>3.75</td>\n",
       "      <td>cash</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 03:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Troy Fisher</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>cash</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 19:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Angela Leach</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.555</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 09:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Brandon Monroe</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>3.75</td>\n",
       "      <td>credit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 21:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Daniel Garcia</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.25</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3.400</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 22:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Jason Martin</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3.285</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-02 12:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Nathaniel Morris</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>3.75</td>\n",
       "      <td>credit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-03 16:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Diana Jones</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>4.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>4.185</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-03 05:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Tracey West</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>3.75</td>\n",
       "      <td>debit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-05 03:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Sara Parker</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.45</td>\n",
       "      <td>debit</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>3.115</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-05 12:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Seth Allen</td>\n",
       "      <td>Cinnamon Dolce Latte</td>\n",
       "      <td>3.65</td>\n",
       "      <td>credit</td>\n",
       "      <td>260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-01 20:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Donna Olson</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.45</td>\n",
       "      <td>debit</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.560</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-01 16:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Jacob Brock</td>\n",
       "      <td>White Chocolate Mocha</td>\n",
       "      <td>4.45</td>\n",
       "      <td>cash</td>\n",
       "      <td>360</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>3.115</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-01 21:04:05</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Stacy Roberts</td>\n",
       "      <td>Caramel Macchiato</td>\n",
       "      <td>4.75</td>\n",
       "      <td>cash</td>\n",
       "      <td>250</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>3.325</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_employer           timestamp name_employer       name_client  \\\n",
       "0             1 2020-08-04 12:04:05          Alex      Aaron Murphy   \n",
       "1             1 2020-08-04 23:04:05          Alex     Eugene Maddox   \n",
       "2             1 2020-08-04 08:04:05          Alex  Jonathan Bradley   \n",
       "3             1 2020-08-04 05:04:05          Alex       Thomas Pace   \n",
       "4             1 2020-08-04 20:04:05          Alex      Thomas Stein   \n",
       "5             1 2020-08-04 03:04:05          Alex       Troy Fisher   \n",
       "6             1 2020-08-02 19:04:05          Alex      Angela Leach   \n",
       "7             1 2020-08-02 09:04:05          Alex    Brandon Monroe   \n",
       "8             1 2020-08-02 21:04:05          Alex     Daniel Garcia   \n",
       "9             1 2020-08-02 22:04:05          Alex      Jason Martin   \n",
       "10            1 2020-08-02 12:04:05          Alex  Nathaniel Morris   \n",
       "11            1 2020-08-03 16:04:05          Alex       Diana Jones   \n",
       "12            1 2020-08-03 05:04:05          Alex       Tracey West   \n",
       "13            1 2020-08-05 03:04:05          Alex       Sara Parker   \n",
       "14            1 2020-08-05 12:04:05          Alex        Seth Allen   \n",
       "15            1 2020-08-01 20:04:05          Alex       Donna Olson   \n",
       "16            1 2020-08-01 16:04:05          Alex       Jacob Brock   \n",
       "17            1 2020-08-01 21:04:05          Alex     Stacy Roberts   \n",
       "\n",
       "             product_name  product_price  payment  calories  percent_carbo  \\\n",
       "0       Caramel Macchiato           4.45    debit       250       0.140000   \n",
       "1   White Chocolate Mocha           4.75   credit       360       0.147222   \n",
       "2   White Chocolate Mocha           3.75     cash       360       0.147222   \n",
       "3   White Chocolate Mocha           3.75    debit       360       0.147222   \n",
       "4   White Chocolate Mocha           3.75     cash       360       0.147222   \n",
       "5    Cinnamon Dolce Latte           3.65     cash       260       0.153846   \n",
       "6    Cinnamon Dolce Latte           3.65   credit       260       0.153846   \n",
       "7       Caramel Macchiato           3.75   credit       250       0.140000   \n",
       "8    Cinnamon Dolce Latte           4.25   credit       260       0.153846   \n",
       "9    Cinnamon Dolce Latte           3.65   credit       260       0.153846   \n",
       "10      Caramel Macchiato           3.75   credit       250       0.140000   \n",
       "11   Cinnamon Dolce Latte           4.65   credit       260       0.153846   \n",
       "12  White Chocolate Mocha           3.75    debit       360       0.147222   \n",
       "13      Caramel Macchiato           4.45    debit       250       0.140000   \n",
       "14   Cinnamon Dolce Latte           3.65   credit       260       0.153846   \n",
       "15  White Chocolate Mocha           4.45    debit       360       0.147222   \n",
       "16  White Chocolate Mocha           4.45     cash       360       0.147222   \n",
       "17      Caramel Macchiato           4.75     cash       250       0.140000   \n",
       "\n",
       "    final_price  year  month  day  \n",
       "0         3.560  2020      8    4  \n",
       "1         4.275  2020      8    4  \n",
       "2         3.000  2020      8    4  \n",
       "3         3.000  2020      8    4  \n",
       "4         3.375  2020      8    4  \n",
       "5         2.920  2020      8    4  \n",
       "6         2.555  2020      8    2  \n",
       "7         2.625  2020      8    2  \n",
       "8         3.400  2020      8    2  \n",
       "9         3.285  2020      8    2  \n",
       "10        3.375  2020      8    2  \n",
       "11        4.185  2020      8    3  \n",
       "12        2.625  2020      8    3  \n",
       "13        3.115  2020      8    5  \n",
       "14        2.920  2020      8    5  \n",
       "15        3.560  2020      8    1  \n",
       "16        3.115  2020      8    1  \n",
       "17        3.325  2020      8    1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\">>> Historical Feature Store:\")\n",
    "hive_context.sql(\"select * from default.starbucks_order_events where name_employer='Alex';\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
